\documentclass{beamer}

\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage{graphicx}
\usepackage[font=tiny,labelfont=bf]{caption}
\usepackage{hyperref}
\usepackage{tikz}

\hypersetup{colorlinks=true, linkcolor=black, urlcolor=blue}

\usetheme{Boadilla}

\graphicspath{ {./pics} }

\title[ML for SE]{Machine Learning for Software Engineering}
\subtitle{ISW2 project a.y. 2023/2024}
\author[Stefano Belli, 0350116]{Stefano Belli, matricola 0350116}
\institute[uniroma2]{Università degli Studi di Roma "Tor Vergata"}
\date{}

\usefonttheme[onlymath]{serif}

\newcommand{\dflvspace}{\vspace{10pt}}

\renewcommand{\footnotesize}{\tiny}

\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{section in toc}{%
  {\color{blue!70!black}\inserttocsectionnumber.}~\inserttocsection}
\setbeamercolor{subsection in toc}{bg=white,fg=structure}
\setbeamertemplate{subsection in toc}{%
  \hspace{1.2em}{\color{blue}\rule[0.3ex]{3pt}{3pt}}~\inserttocsubsection\par}

\begin{document}

\begin{frame}[plain]
    \titlepage
\end{frame}

\begin{frame}
    \frametitle{Agenda}
    \fontsize{8pt}{10pt}\selectfont
    \tableofcontents
\end{frame}

\section{Introduzione}
\begin{frame}
	\frametitle{Introduzione}
	
	\begin{itemize}
		\setlength\itemsep{10pt}
	
		\item Nei grandi progetti software, il collaudo è cruciale: avere una buona test suite aiuta a prevenire
		malfunzionamenti spiacevoli per l'utente, permettendo il rilevamento del difetto prima della release.
	
		\item Tuttavia, eseguire numerosi test è dispendioso sia in termini di tempo d'esecuzione dei test sia per
		quanto riguarda la loro progettazione e implementazione: per quali unità conviene focalizzarsi?
		
		\item Per aiutarci a rispondere a queste domande, possiamo usare un modello di machine learning che 
		date informazioni sul codice sorgente, predica se l'unità sia "buggy" o meno
		(e quindi, se generare dei test case per quest'ultima).
	\end{itemize}
\end{frame}

\section{Scopo}
\begin{frame}
	\frametitle{Scopo}
	
	\begin{itemize}
		\setlength\itemsep{10pt}
		
		\item Si vogliono confrontare le prestazioni di tre classificatori (Naive Bayes, IBk, Random Forest) con e
		senza tecniche di feature selection, sampling e cost sensitivity.
		\begin{itemize}
			\item Prediction della buggyness di una classe Java
		\end{itemize}
	
		\item Per la costruzione del dataset (e quindi la comparazione dei classificatori)
		vengono sfruttati i progetti open source Apache BookKeeper e Apache Storm.
	\end{itemize}
\end{frame}

\section{Metodologia}
\subsection{Recupero informazioni su release e tickets da Jira}
\begin{frame}
	\frametitle{Recupero informazioni su release e tickets da Jira}
	
	Dal bug tracker Jira, utilizzato dalla Apache Software Foundation, vengono scaricati, tramite
	la sua REST API, informazioni riguardo alle \underline{release} e ai \underline{ticket} che siano di tipo
	\textit{"bug"}, il cui stato sia \textit{"closed"} o \textit{"resolved"}, e la risoluzione \textit{"fixed"}
	
	\dflvspace
	
	Le informazioni (in particolare le date) su questi tipi di ticket serviranno 
	poi per determinare quali classi sono buggate, in quali release.
	
	\dflvspace

	In Jira, nell'oggetto JSON della risposta, per ogni ticket, sono di particolare interesse questi campi 
	(che ci permetteranno di capire le release affette dal bug):
	\begin{itemize}
		\item L'array \textit{fields.version}
		che contiene le informazioni sulle release affette dal bug (affected versions)
		\item La stringa \textit{fields.created} che è la data di apertura del ticket
		\item La stringa \textit{fields.resolutiondate} che è la data di risoluzione del bug
	\end{itemize}
\end{frame}

\subsection{Ciclo di vita del difetto}
\begin{frame}
	\frametitle{Ciclo di vita del difetto}
	
	\fontsize{10pt}{10pt}\selectfont
	
	Al fine di determinare le versioni affette dal bug, definiamo:
	\begin{itemize}
		\item L' \textbf{injected version} (\textit{IV})
		che è il numero di versione in cui è stato introdotto il bug
		\item L' \textbf{opening version} (\textit{OV}) 
		che è il numero di versione in cui è stato aperto il ticket relativo al bug
		\item La \textbf{fixed version} (\textit{FV}) 
		che è il numero di versione in cui è stato risolto il bug
	\end{itemize}
	
	\begin{center}
	\begin{tikzpicture}
		\draw (0,0) -- (2,0);
		\draw[color=red] (2,0) -- (5,0);
		\draw[color=red] (5,0) -- (8,0);
		\draw[->] (8,0) -- (11,0);
		\draw[fill=red] (2,0) circle (2pt) 
							node[above]{\small{$IV$}} 
							node[below]{\tiny{$2$}};
		\draw[fill=red] (5,0) circle (2pt) 
							node[above]{\small{$OV$}}
							node[below]{\tiny{$5$}};
		\draw[fill=white] (8,0) circle (2pt) 
							node[above]{\small{$FV$}}
							node[below]{\tiny{$8$}};
	\end{tikzpicture}
	\end{center}
	
	Tutte e 3 le \textit{IV},\textit{OV} e \textit{FV} permettono di individuare il "ciclo di vita" completo del
	bug, che è presente da \textit{IV} (incluso) fino a \textit{FV} (escluso).
	\begin{alertblock}{Problema}
	Le API di Jira, forniscono sempre informazioni riguardo alla creazione del ticket e alla sua risoluzione
	(permettendo di determinare, rispettivamente: opening e fixed version), 
	ma non sempre rispetto alle affected versions, non permettendo sempre di individuare la injected version!
	\end{alertblock}
\end{frame}

\subsection{Utilizzo della tecnica proportion}
\begin{frame}
	\frametitle{Utilizzo della tecnica proportion}
	Se l'injected version non è nota, per un certo bug
	possiamo sfruttare il \textbf{proportion} per stimare l'\textit{IV}:
	
	\dflvspace
	
	\begin{align*}
	p = \frac{FV-IV}{FV-OV}\;\;\;\;\Rightarrow\;\;\;\;IV = FV - (FV - OV)\cdot p
	\end{align*}
	
	\dflvspace
	
	\begin{exampleblock}{Applicazione}
	A partire dai bug la cui \textit{IV} è nota, calcoliamo $p$ (prima formula). 
	Poi, avendo appena calcolato la costante di proporzionalità $p$, per il bug di cui
	\underline{non} si conosce \textit{IV}, si applica la seconda formula, in modo da determinarla.
	\end{exampleblock}
\end{frame}

\subsection{Metodi di utilizzo di proportion}
\begin{frame}
	\frametitle{Metodi di utilizzo di proportion}
	Viene utilizzato proportion con le tecniche:
	\begin{itemize}
		\item \textbf{Cold start}: se il numero di tickets utilizzabili ai fini del calcolo di $p$ è minore
		di 5, si calcola la media di $p$ sui ticket per ognuno dei seguenti progetti Apache: 
		Avro, OpenJPA, Syncope, Tajo e ZooKeeper. 
		Infine si effettua la mediana su queste 5 medie, ottenendoil valore di $p$ finale.
		\item \textbf{Incremental}: se il numero di tickets utilizzabili ai fini del calcolo di $p$ è maggiore o
		uguale a 5: $p$ è calcolato effettuando la media delle proporzionalità $p$ di tutti i bug precedenti 
		(che hanno \textit{IV})
		rispetto a quello considerato attualmente, di cui bisogna stimare \textit{IV}.
	\end{itemize}
\end{frame}

\subsection{Costruzione del dataset: metriche}
\begin{frame}
	\frametitle{Costruzione del dataset: metriche}
	
	\fontsize{9pt}{10pt}\selectfont
	
	% JGit, commit, releases unione info da jira e git
	\begin{itemize}
	
		\item Viene usato JGit al fine di poter manipolare un 
		repository Git direttamente tramite metodi Java: possiamo
		collezionare informazioni su commit e quindi anche sul codice sorgente 
		(esclusivamente classi Java) del repo di interesse.
		
		\item Dalle informazioni ricavate da Git, si possono calcolare delle metriche di interesse
		su un certo file Java che verranno poi utilizzate dal classificatore ai
		fini della predizione
	\end{itemize}
	
	\dflvspace
	
	Le metriche di interesse scelte sono le seguenti:
	
	\dflvspace
	
	\centering
	\begin{tabular}{|l|l|}
		\hline
		\textbf{Metrica} & \textbf{Descrizione} \\
		\hline
		\hline 
		LOC & Numero di linee di codice\\
		\hline
		LOC added & Somma di LOC aggiunte sulle revisioni\\
		\hline
		Avg. LOC added & Media di LOC aggiunte sulle revisioni\\
		\hline
		Max. LOC added & Numero massimo di LOC aggiunte tra le revisioni\\
		\hline
		Churn & Somma di LOC aggiunte e rimosse sulle revisioni\\
		\hline
		Avg. churn & Media di LOC aggiunte e rimosse sulle revisioni\\
		\hline
		Max. churn & Numero massimo di LOC aggiunte e rimosse tra le revisioni\\
		\hline
		Avg. chg. set & Media di file cambiati insieme sulle revisioni\\
		\hline
		Max. chg. set & Numero massimo di file cambiati insieme sulle revisioni\\
		\hline
		Num. of authors & Numero di autori\\
		\hline
		Num. of revs & Numero di revisioni\\
		\hline
	\end{tabular}
	
	
\end{frame}

\subsection{Costruzione del dataset: buggyness e snoring}
\begin{frame}
	\frametitle{Costruzione del dataset: buggyness e snoring}
	
	\begin{itemize}
		\item Le informazioni ottenute da Jira vengono "collegate" a quelle ricavate da Git (ticket e release vengono 
		associati ai commit).
		
		\item Il dataset, oltre ad essere composto dalle metriche di interesse appena elencate, 
		ha nella prima e seconda colonna rispettivamente
		la versione del progetto Apache in esame, il path al file Java interessato , nel mezzo le metriche,
		e come ultima colonna la buggyness.
		
		\item La \textbf{buggyness}
		(variabile binaria che può assumere valore "YES" o "NO" e che il classificatore deve predirre) viene 
		determinata grazie al collegamento delle informazioni ricavate tra Jira e Git.
		\begin{itemize}
			\item Una classe Java è \textit{buggy} se la versione $v$ in cui ricade è compresa nell'intervallo 
			$IV \le v < FV$
		\end{itemize}
	\end{itemize}
	
	\begin{alertblock}{Snoring}
	Al fine di ridurre l'effetto dello \textbf{snoring}, ovvero bug dormienti non rilevati, sono stati eliminati
	tutti i dati relativi alla seconda metà delle releases. Dare in pasto al classificatore dati affetti da
	snoring può comprometterne le prestazioni.
	\end{alertblock}
	
\end{frame}

\subsection{Classificatori e tecniche considerate}
\begin{frame}
	\frametitle{Classificatori e tecniche considerate}
	
	\fontsize{7pt}{8pt}\selectfont
	
	Sono stati utilizzati 3 classificatori diversi\dots
	\begin{itemize}
		\item Random forest
		\item Naive Bayes
		\item IBk
	\end{itemize}
	
	\begin{columns}[T]
		\begin{column}{0.5\linewidth}
		\dots ognuno con le seguenti tecniche\dots
		
		\textbf{Feature selection}
		\begin{itemize}
			\item Nessuna tecnica di feature selection
			\item Best first backward
		\end{itemize}
	
		\textbf{Sampling}
		\begin{itemize}
			\item Nessuna tecnica di sampling
			\item SMOTE
			\item Undersampling
		\end{itemize}
	
		\textbf{Cost sensitivity}
		\begin{itemize}
			\item Nessuna tecnica di cost sensitivity
			\item Sensitive Learning
		\end{itemize}
		\end{column}
	
		\begin{column}{0.5\linewidth}
		\dots combinate come segue:
		\begin{tabular}{|c|}
			\hline
			Nessuna tecnica utilizzata\\
			\hline
			Solo sensitive learning\\
			\hline
			Solo best first backward\\
			\hline
			Solo undersampling\\
			\hline 
			Solo SMOTE\\
			\hline
			Best first backward e sens. learning\\
			\hline
			Best first backward e undersampling\\
			\hline
			Best first backward e SMOTE\\
			\hline
		\end{tabular}
		\end{column}
	\end{columns}
	\dflvspace
	La \underline{valutazione} viene effettuata tramite l'ausilio 4 metriche: 
	\textbf{F1-score} 
	(media armonica tra precision e recall, il cui valore sta nel range $[0,1]$: 
	è 1 se lo sono sia precision che recall, è 0 alla stessa condizione),
	\textbf{Kappa}, \textbf{AUC}, 
	\textbf{NPofB20} (percentuale di bug che
	possono essere trovati analizzando il top 20\% di LOC. Il ranking, per definire
	il \textit{"top 20\% di LOC"}
	è effettuato sulla prob. pred. di buggyness diviso la size dell'unità
	presa in considerazione).
	
	Ne viene valutato, inoltre, il \textbf{costo}: $CFN \cdot FN + CFP \cdot FP$ con
	$CFN=10,\;CFP=1$
\end{frame}

\subsection{Evaluation con walk forward}
\begin{frame}
	\frametitle{Evaluation con walk forward}
	
	\fontsize{9pt}{10pt}\selectfont
	
	Lo strumento utilizzato per valutare le prestazioni dei classificatori (con o senza tecniche) è
	una tecnica di tipo time-series: walk forward.
	
	\begin{itemize}
		\item Nella figura sottostante è presente un esempio di esecuzione dell'evaluation.
	
		\item Nel nostro caso, la prima run, non viene effettuata a prescindere dato che non abbiamo un training set con cui addestrare
		un classificatore e quindi viene ritenuta inutile.
		\item Le run per BookKeeper partono dalla run 3 
		(2 training rels. + 1 testing rel), 
		mentre le run per Storm partono dalla run 4 (3 training rels.  + 1 testing rel.)
		\begin{itemize}
			\item Essendo una tecnica time-series, i dati disponibili fino alle release di training non rivelano
			alcuna classe buggy, impedendo l'addestramento del classificatore
		\end{itemize}
	\end{itemize}
	
	\begin{center}
	\includegraphics[width=4cm, height=2.25cm]{walkforward}
	\end{center}
	
	\fontsize{8pt}{10pt}\selectfont
	
	Il \textbf{training set} deve riflettere l'utilizzo reale del classificatore, 
	può essere affetto da snoring: non utilizziamo i dati del futuro per determinare 
	la buggyness (la tecnica è time-series), al contrario, per il \textbf{testing set}
	vengono utilizzati tutti i dati a nostra disposizione, deve essere
	il più accurato possibile e non deve essere affetto da snoring (idealmente)
\end{frame}

\section{Risultati}
\subsection{Risultati per BookKeeper}
\begin{frame}
	\frametitle{Risultati per BookKeeper: F1-score}
	
	\fontsize{7pt}{8pt}\selectfont
	
	Tra tutte le soluzioni proposte, \textbf{IBk senza
	feature selection, con SMOTE, no cost sensitivity, sembra essere la migliore}.
	
	\centering
	\begin{figure}
	\includegraphics[width=10cm, height=6cm]{bookkeeper-f1score}
	\caption{Il box plot verde è per Random forest, rosso per Naive Bayes, blu per IBk}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Risultati per BookKeeper: Kappa}
	
	\fontsize{7pt}{8pt}\selectfont
	
	I kappa peggiori sono sicuramente quelli di Naive Bayes 
	senza feature selection con SMOTE (no cost sensitivity), Naive Bayes senza
	applicazione di feature selection, senza balancing, no cost sensitivity e 
	Naive Bayes senza applicazione di feature selection, senza balancing, sens.
	learning.
	\textbf{IBk si riconferma il migliore, 
	in particolare con l'applicazione di feature 
	selection, no balancing, no cost sensitivity} 
	(anche se usare sens. learning con IBk con feature
	selection, no balancing, non sembra essere una
	cattiva idea: il valore massimo è inferiore, ma non troppo e
	rispetto al precedente ha un
	valore minimo e mediana leggermente più alti)
	
	\centering
	\begin{figure}
	\includegraphics[width=10cm, height=6cm]{bookkeeper-kappa}
	\caption{Il box plot verde è per Random forest, rosso per Naive Bayes, blu per IBk}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Risultati per BookKeeper: AUC}
	
	\fontsize{7pt}{8pt}\selectfont
	
	Naive Bayes sembra essere quello che ha i valori massimi più alti, ma anche i
	valori minimi e mediane più bassi.
	Per quanto riguarda IBk, la mediana è decisamente più elevata rispetto agli
	altri due classificatori, con tutte le combinazioni delle tecniche.
	\textbf{Random forest con SMOTE, no feature selection, no cost sensitivity,
	sembra essere la scelta migliore} in questo caso: è vero che, ad esempio, rispetto
	a IBk con SMOTE, no cost sensitivity, no balancing,
	la mediana di RF con SMOTE, no feature selection, no cost sensitivity,
	è più bassa ma il valore massimo e minimo sono più elevati.
	
	\centering
	\begin{figure}
	\includegraphics[width=10cm, height=6cm]{bookkeeper-auc}
	\caption{Il box plot verde è per Random forest, rosso per Naive Bayes, blu per IBk}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Risultati per BookKeeper: NPofB20}
	
	\centering
	\begin{figure}
	\includegraphics[width=10cm, height=6cm]{bookkeeper-npofb20}
	\caption{Il box plot verde è per Random forest, rosso per Naive Bayes, blu per IBk}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Risultati per BookKeeper: costi}
	
	\centering
	\begin{figure}
	\includegraphics[width=10cm, height=6cm]{bookkeeper-cost}
	\caption{Il box plot verde è per Random forest, rosso per Naive Bayes, blu per IBk}
	\end{figure}
\end{frame}

\subsection{Risultati per Storm}
\begin{frame}
	\frametitle{Risultati per Storm: F1-score}
	
	\centering
	\begin{figure}
	\includegraphics[width=10cm, height=6cm]{storm-f1score}
	\caption{Il box plot verde è per Random forest, rosso per Naive Bayes, blu per IBk}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Risultati per Storm: Kappa}
	
	\centering
	\begin{figure}
	\includegraphics[width=10cm, height=6cm]{storm-kappa}
	\caption{Il box plot verde è per Random forest, rosso per Naive Bayes, blu per IBk}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Risultati per Storm: AUC}
	
	\centering
	\begin{figure}
	\includegraphics[width=10cm, height=6cm]{storm-auc}
	\caption{Il box plot verde è per Random forest, rosso per Naive Bayes, blu per IBk}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Risultati per Storm: NPofB20}
	
	\centering
	\begin{figure}
	\includegraphics[width=10cm, height=6cm]{storm-npofb20}
	\caption{Il box plot verde è per Random forest, rosso per Naive Bayes, blu per IBk}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Risultati per Storm: costi}
	
	\centering
	\begin{figure}
	\includegraphics[width=10cm, height=6cm]{storm-cost}
	\caption{Il box plot verde è per Random forest, rosso per Naive Bayes, blu per IBk}
	\end{figure}
\end{frame}

\section{Conclusioni e minacce alla validità}
\begin{frame}
	\frametitle{Conclusioni e minacce alla validità}
	
\end{frame}

\section{Links}
\begin{frame}
	\frametitle{Links}
	
	\begin{itemize}
		\item GitHub: \url{https://github.com/StefanoBelli/isw2-deliverable}
		\item SonarCloud: \url{https://sonarcloud.io/project/overview?id=StefanoBelli_isw2-deliverable}
	\end{itemize}
	
\end{frame}

\begin{frame}[noframenumbering, plain]
    \frametitle{}
    
    \fontsize{30pt}{10pt}\selectfont
    \centering
    \textbf{Grazie per l'attenzione!}
    
\end{frame}


\end{document}
